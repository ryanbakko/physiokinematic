Instructions for computing on Scylla
Trey Wenger - Nov 2024
====================================

- Log into scylla via SSH. You will probably need to be connected
to "eduroam" or WiscVPN.

ssh username@scylla.astro.wisc.edu

- Download miniconda

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

- Set-up environments, e.g.:

conda create --name galstruct -c conda-forge pytensor pymc pip
conda activate galstruct
python -m pip install -e .

- "scylla" is just the log-in node for the computing cluster. In
general, you do not want to run any intensive or long-running
computations on the log-in node. Instead, you can request an
interactive session on one of the cluster nodes, or you can submit
jobs to be run on one or more of the cluster nodes simultaneously.

- To start an interactive session and access a jupyter-notebook:
--> On your local machine, SSH to scylla while also forwarding the
    port to be used by jupyter-notebook:

    ssh -L 9000:localhost:9000 username@scylla.astro.wisc.edu

--> Now on scylla, you can request an interactive node. Note that
    you must keep this terminal open to maintain the connection to
    the node. Alternatively, you can use "screen" to create a terminal
    instance from which you can "disconnect" and "reconnect". For
    example:

    # start the "screen" session
    screen

    # check out an interactive node for 7 days, 0 hours
    salloc --nodes=1 --time=7-0

    # list allocated resources to your username
    squeue -u username

    # note which "node" you are assigned (e.g., scylla-node01)
    # log in to that node, forwarding the port used by jupyter-notebook
    ssh -L 9000:localhost:9000 username@scylla-node01

    # activate conda environment, start notebook on given port
    conda activate galstruct
    jupyter-notebook --no-browser --port=9000

    # note the jupyter-notebook URL listed and navigate to that
    # address in your browser on your local machine.

    # press ctrl-a-d (hold control, then press a followed by d)
    # to detach from the "screen" session.
    # you will be returned to your original terminal, which is on
    # the log-in node scylla

    # you will need to keep that connection open as long as you
    # are working. When you need to re-connect to a screen session,
    # the following command will either re-connect you to the only
    # screen session if there is only one, otherwise it will list the
    # available screen sessions and you can choose which one to
    # connect to.
    screen -r # or screen -r <ID> to connect to a specific session

If you are developing code and de-bugging using an interactive
session on scylla, then you will need to write the code locally,
push it to GitHub, then pull it from GitHub onto scylla.

--> Alternatively, you can submit non-interactive jobs to the
computing cluster to run many different programs in parallel.
You have to create a "SLURM" script. Many details can be found
online: https://www.arch.jhu.edu/short-tutorial-how-to-create-a-slurm-script/

Here's an example:

#!/bin/bash
#SBATCH --chdir="/home/twenger/tigress_hi"
#SBATCH --job-name="21sponge"
#SBATCH --output="logs/%x.%j.%N.out"
#SBATCH --error="logs/%x.%j.%N.err"
#SBATCH --mail-type=ALL
#SBATCH --mail-user=twenger2@wisc.edu
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --export=ALL
#SBATCH --time 72:00:00
#SBATCH --array=0-56

eval "$(conda shell.bash hook)"
conda activate caribou_hi

# temporary pytensor compiledir
tmpdir=`mktemp -d`
echo "starting to analyze $SLURM_ARRAY_TASK_ID"
PYTENSOR_FLAGS="base_compiledir=$tmpdir" python scripts/run_21sponge.py $SLURM_ARRAY_TASK_ID
rm -rf $tmpdir

Execute this file via:
sbatch <filename>
